{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Deep Learning gender from name - RNN LSTMs </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we will use an LSTM RNN to learn gender as f(name). we will use a stacked LSTM with many-to-one architecture feeding charecter data_sets and predicting a binary outcome M/F. loss function used will be binary_crossentropy (a special case of categorical_crossentropy with m=2) and using adam optimizer (modified SGD) sample data_set /output would like this <br> ['r','a','k','e','s','h',' '] - male<br> ['p','r','a','d','e','e','p'] - male<br> ['g','a','n','g','a',' '] - female<br> and so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"LSTM_RNN_architecture.jpg\" width=\"800\" height=\"600\"/>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "regexp applied\n",
    "[^a-zA-Z0-9 ,.\\r\\n] = remove\n",
    "[ ]+ = ' '\n",
    "[^a-zA-Z ,.\\r\\n] = remove\n",
    "[ ]{3}+ - regex to check where 3 consecutive space occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "maxlen = 30\n",
    "labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv(\"gender_data.csv\",header=None)\n",
    "data_set.columns = ['name','m_or_f']\n",
    "data_set['namelen']= [len(str(i)) for i in data_set['name']]\n",
    "data_set1 = data_set[(data_set['namelen'] >= 2) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m_or_f\n",
       "f    6705\n",
       "m    8475\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set1.groupby('m_or_f')['name'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = data_set['name']\n",
    "gender = data_set['m_or_f']\n",
    "vocab = set(' '.join([str(i) for i in names]))\n",
    "vocab.add('END')\n",
    "len_vocab = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([' ', '.', '1', '0', '3', '2', '5', '4', '7', '6', '9', '8', 'END', 'a', 'c', 'b', 'e', 'd', 'g', 'f', 'i', 'h', 'k', 'j', 'm', 'l', 'o', 'n', 'q', 'p', 's', 'r', 'u', 't', 'w', 'v', 'y', 'x', 'z'])\n",
      "vocab length is  39\n",
      "length of input is  15226\n"
     ]
    }
   ],
   "source": [
    "print(vocab)\n",
    "print(\"vocab length is \",len_vocab)\n",
    "print (\"length of data_set is \",len(data_set1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_index = dict((c, i) for i, c in enumerate(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '.': 1, '1': 2, '0': 3, '3': 4, '2': 5, '5': 6, '4': 7, '7': 8, '6': 9, '9': 10, '8': 11, 'END': 12, 'a': 13, 'c': 14, 'b': 15, 'e': 16, 'd': 17, 'g': 18, 'f': 19, 'i': 20, 'h': 21, 'k': 22, 'j': 23, 'm': 24, 'l': 25, 'o': 26, 'n': 27, 'q': 28, 'p': 29, 's': 30, 'r': 31, 'u': 32, 't': 33, 'w': 34, 'v': 35, 'y': 36, 'x': 37, 'z': 38}\n"
     ]
    }
   ],
   "source": [
    "print(char_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "msk = np.random.rand(len(data_set1)) < 0.8\n",
    "train = data_set1[msk]\n",
    "test = data_set1[~msk]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take data_set upto max and truncate rest\n",
    "#encode to vector space(one hot encoding)\n",
    "#padd 'END' to shorter sequences\n",
    "train_X = []\n",
    "trunc_train_name = [str(i)[0:30] for i in train.name]\n",
    "for i in trunc_train_name:\n",
    "    tmp = [char_index[j] for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(char_index[\"END\"])\n",
    "    train_X.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12198, 30)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_flag(i):\n",
    "    tmp = np.zeros(39);\n",
    "    tmp[i] = 1\n",
    "    return(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_flag(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modify the code above to also convert each index to one-hot encoded representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take data_set upto max and truncate rest\n",
    "#encode to vector space(one hot encoding)\n",
    "#padd 'END' to shorter sequences\n",
    "#also convert each index to one-hot encoding\n",
    "train_X = []\n",
    "train_Y = []\n",
    "trunc_train_name = [str(i)[0:maxlen] for i in train.name]\n",
    "for i in trunc_train_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    train_X.append(tmp)\n",
    "for i in train.m_or_f:\n",
    "    if i == 'm':\n",
    "        train_Y.append([1,0])\n",
    "    else:\n",
    "        train_Y.append([0,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12198, 30, 39)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12198, 2)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(train_Y).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build model in keras ( a stacked LSTM model with many-to-one arch ) here 30 sequence and 2 output each for one category(m/f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "#build the model: 2 stacked LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, data_set_shape=(maxlen,len_vocab)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = []\n",
    "test_Y = []\n",
    "trunc_test_name = [str(i)[0:maxlen] for i in test.name]\n",
    "for i in trunc_test_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    test_X.append(tmp)\n",
    "for i in test.m_or_f:\n",
    "    if i == 'm':\n",
    "        test_Y.append([1,0])\n",
    "    else:\n",
    "        test_Y.append([0,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3028, 30, 39)\n",
      "(3028, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(test_X).shape)\n",
    "print(np.asarray(test_Y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12198 samples, validate on 3028 samples\n",
      "Epoch 1/10\n",
      "12198/12198 [==============================] - 146s - loss: 0.5867 - acc: 0.6849 - val_loss: 0.5630 - val_acc: 0.7081\n",
      "Epoch 2/10\n",
      "12198/12198 [==============================] - 145s - loss: 0.5312 - acc: 0.7336 - val_loss: 0.5880 - val_acc: 0.6909\n",
      "Epoch 3/10\n",
      "12198/12198 [==============================] - 145s - loss: 0.5217 - acc: 0.7395 - val_loss: 0.4982 - val_acc: 0.7576\n",
      "Epoch 4/10\n",
      "12198/12198 [==============================] - 145s - loss: 0.4866 - acc: 0.7620 - val_loss: 0.4823 - val_acc: 0.7652\n",
      "Epoch 5/10\n",
      "12198/12198 [==============================] - 145s - loss: 0.4682 - acc: 0.7791 - val_loss: 0.4918 - val_acc: 0.7632\n",
      "Epoch 6/10\n",
      "12198/12198 [==============================] - 145s - loss: 0.4583 - acc: 0.7878 - val_loss: 0.4771 - val_acc: 0.7678\n",
      "Epoch 7/10\n",
      "12198/12198 [==============================] - 144s - loss: 0.4525 - acc: 0.7862 - val_loss: 0.4926 - val_acc: 0.7632\n",
      "Epoch 8/10\n",
      "12198/12198 [==============================] - 145s - loss: 0.4492 - acc: 0.7919 - val_loss: 0.4677 - val_acc: 0.7794\n",
      "Epoch 9/10\n",
      "12198/12198 [==============================] - 144s - loss: 0.4228 - acc: 0.8058 - val_loss: 0.4745 - val_acc: 0.7797\n",
      "Epoch 10/10\n",
      "12198/12198 [==============================] - 145s - loss: 0.4085 - acc: 0.8154 - val_loss: 0.4534 - val_acc: 0.7893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ff409ba10>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=1000\n",
    "model.fit(train_X, train_Y,batch_size=batch_size,nb_epoch=10,validation_data=(test_X, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3028/3028 [==============================] - 16s    \n",
      "Test score: 0.453434576998\n",
      "Test accuracy: 0.789299867978\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(test_X, test_Y)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[\"sandhya\",\"jaspreet\",\"rajesh\"]\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.62356585,  0.37643418],\n",
       "       [ 0.72094178,  0.27905828],\n",
       "       [ 0.90337974,  0.09662029]], dtype=float32)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets train more, clearly some very simple female names it doesnt get right like mentioned above (inspite it exists in training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12198 samples, validate on 3028 samples\n",
      "Epoch 1/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.4107 - acc: 0.8137 - val_loss: 0.4408 - val_acc: 0.7966\n",
      "Epoch 2/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.3912 - acc: 0.8254 - val_loss: 0.4479 - val_acc: 0.7936\n",
      "Epoch 3/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.3927 - acc: 0.8228 - val_loss: 0.4511 - val_acc: 0.7982\n",
      "Epoch 4/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.3730 - acc: 0.8344 - val_loss: 0.4253 - val_acc: 0.8071\n",
      "Epoch 5/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.3640 - acc: 0.8396 - val_loss: 0.4240 - val_acc: 0.8164\n",
      "Epoch 6/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.3490 - acc: 0.8505 - val_loss: 0.4183 - val_acc: 0.8180\n",
      "Epoch 7/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.3411 - acc: 0.8542 - val_loss: 0.4089 - val_acc: 0.8243\n",
      "Epoch 8/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.3396 - acc: 0.8529 - val_loss: 0.4026 - val_acc: 0.8184\n",
      "Epoch 9/50\n",
      "12198/12198 [==============================] - 146s - loss: 0.3294 - acc: 0.8590 - val_loss: 0.3781 - val_acc: 0.8451\n",
      "Epoch 10/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.3159 - acc: 0.8684 - val_loss: 0.3935 - val_acc: 0.8332\n",
      "Epoch 11/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.3025 - acc: 0.8736 - val_loss: 0.3912 - val_acc: 0.8425\n",
      "Epoch 12/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2921 - acc: 0.8808 - val_loss: 0.3981 - val_acc: 0.8408\n",
      "Epoch 13/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.2885 - acc: 0.8800 - val_loss: 0.4018 - val_acc: 0.8336\n",
      "Epoch 14/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2823 - acc: 0.8853 - val_loss: 0.3687 - val_acc: 0.8464\n",
      "Epoch 15/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2763 - acc: 0.8879 - val_loss: 0.3866 - val_acc: 0.8606\n",
      "Epoch 16/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2653 - acc: 0.8933 - val_loss: 0.3820 - val_acc: 0.8554\n",
      "Epoch 17/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2573 - acc: 0.8970 - val_loss: 0.3962 - val_acc: 0.8471\n",
      "Epoch 18/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2651 - acc: 0.8919 - val_loss: 0.3756 - val_acc: 0.8501\n",
      "Epoch 19/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2539 - acc: 0.8982 - val_loss: 0.3837 - val_acc: 0.8491\n",
      "Epoch 20/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.2576 - acc: 0.8970 - val_loss: 0.4036 - val_acc: 0.8494\n",
      "Epoch 21/50\n",
      "12198/12198 [==============================] - 146s - loss: 0.2476 - acc: 0.9010 - val_loss: 0.4013 - val_acc: 0.8471\n",
      "Epoch 22/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.2485 - acc: 0.8985 - val_loss: 0.3795 - val_acc: 0.8587\n",
      "Epoch 23/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.2273 - acc: 0.9087 - val_loss: 0.3745 - val_acc: 0.8583\n",
      "Epoch 24/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2287 - acc: 0.9074 - val_loss: 0.3830 - val_acc: 0.8570\n",
      "Epoch 25/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2205 - acc: 0.9097 - val_loss: 0.3870 - val_acc: 0.8563\n",
      "Epoch 26/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2133 - acc: 0.9150 - val_loss: 0.3778 - val_acc: 0.8656\n",
      "Epoch 27/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.2024 - acc: 0.9225 - val_loss: 0.3910 - val_acc: 0.8646\n",
      "Epoch 28/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1911 - acc: 0.9244 - val_loss: 0.4067 - val_acc: 0.8570\n",
      "Epoch 29/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.1869 - acc: 0.9241 - val_loss: 0.4113 - val_acc: 0.8633\n",
      "Epoch 30/50\n",
      "12198/12198 [==============================] - 147s - loss: 0.1897 - acc: 0.9229 - val_loss: 0.3766 - val_acc: 0.8662\n",
      "Epoch 31/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1786 - acc: 0.9279 - val_loss: 0.4527 - val_acc: 0.8623\n",
      "Epoch 32/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1728 - acc: 0.9311 - val_loss: 0.4064 - val_acc: 0.8633\n",
      "Epoch 33/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.1893 - acc: 0.9250 - val_loss: 0.3870 - val_acc: 0.8613\n",
      "Epoch 34/50\n",
      "12198/12198 [==============================] - 146s - loss: 0.1880 - acc: 0.9253 - val_loss: 0.3886 - val_acc: 0.8692\n",
      "Epoch 35/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1672 - acc: 0.9344 - val_loss: 0.4596 - val_acc: 0.8504\n",
      "Epoch 36/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.1610 - acc: 0.9329 - val_loss: 0.4256 - val_acc: 0.8669\n",
      "Epoch 37/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1596 - acc: 0.9344 - val_loss: 0.4235 - val_acc: 0.8705\n",
      "Epoch 38/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.1651 - acc: 0.9333 - val_loss: 0.4543 - val_acc: 0.8596\n",
      "Epoch 39/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1557 - acc: 0.9382 - val_loss: 0.4427 - val_acc: 0.8662\n",
      "Epoch 40/50\n",
      "12198/12198 [==============================] - 144s - loss: 0.1558 - acc: 0.9371 - val_loss: 0.4607 - val_acc: 0.8530\n",
      "Epoch 41/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1461 - acc: 0.9410 - val_loss: 0.4565 - val_acc: 0.8633\n",
      "Epoch 42/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1365 - acc: 0.9444 - val_loss: 0.4703 - val_acc: 0.8600\n",
      "Epoch 43/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1310 - acc: 0.9461 - val_loss: 0.5031 - val_acc: 0.8705\n",
      "Epoch 44/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1247 - acc: 0.9480 - val_loss: 0.4818 - val_acc: 0.8643\n",
      "Epoch 45/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1173 - acc: 0.9520 - val_loss: 0.5398 - val_acc: 0.8662\n",
      "Epoch 46/50\n",
      "12198/12198 [==============================] - 146s - loss: 0.1194 - acc: 0.9508 - val_loss: 0.5055 - val_acc: 0.8649\n",
      "Epoch 47/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1230 - acc: 0.9512 - val_loss: 0.5328 - val_acc: 0.8656\n",
      "Epoch 48/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1219 - acc: 0.9491 - val_loss: 0.5247 - val_acc: 0.8696\n",
      "Epoch 49/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1245 - acc: 0.9492 - val_loss: 0.4557 - val_acc: 0.8676\n",
      "Epoch 50/50\n",
      "12198/12198 [==============================] - 145s - loss: 0.1437 - acc: 0.9427 - val_loss: 0.4484 - val_acc: 0.8643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5fe98ba8d0>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=1000\n",
    "model.fit(train_X, train_Y,batch_size=batch_size,nb_epoch=50,validation_data=(test_X, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3028/3028 [==============================] - 16s    \n",
      "Test score: 0.448404541104\n",
      "Test accuracy: 0.864266842879\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(test_X, test_Y)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=\"center\"> lets look at the loss and accuracy chart as a function of epochs </h3><img src=\"loss_charts.bmp\" alt=\"loss charts\" width=\"500\" height=\"350\"/><img src=\"acc_charts.bmp\" alt=\"loss charts\"  width=\"500\" height=\"350\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0859881 ,  0.91401184],\n",
       "       [ 0.96310365,  0.03689628],\n",
       "       [ 0.7148453 ,  0.28515476],\n",
       "       [ 0.02246205,  0.97753793],\n",
       "       [ 0.13607673,  0.86392319],\n",
       "       [ 0.99559009,  0.00440993],\n",
       "       [ 0.05380283,  0.94619709],\n",
       "       [ 0.55060732,  0.44939268],\n",
       "       [ 0.10676169,  0.89323831]], dtype=float32)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[\"sandhya\",\"jaspreet\",\"rajesh\",\"kaveri\",\"aditi deepak\",\"arihant\",\"sasikala\",\"aditi\",\"ragini rajaram\"]\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15557961,  0.84442037],\n",
       "       [ 0.25342518,  0.74657482],\n",
       "       [ 0.8618474 ,  0.13815261]], dtype=float32)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[\"abhi\",\"abhi deepak\",\"mr. abhi\"]\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.33718896,  0.66281104],\n",
       "       [ 0.99896383,  0.00103616],\n",
       "       [ 0.99664474,  0.00335527]], dtype=float32)"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=[\"rajini\",\"rajinikanth\",\"mr. rajini\"]\n",
    "X=[]\n",
    "trunc_name = [i[0:maxlen] for i in name]\n",
    "for i in trunc_name:\n",
    "    tmp = [set_flag(char_index[j]) for j in str(i)]\n",
    "    for k in range(0,maxlen - len(str(i))):\n",
    "        tmp.append(set_flag(char_index[\"END\"]))\n",
    "    X.append(tmp)\n",
    "pred=model.predict(np.asarray(X))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save our model and data\n",
    "model.save_weights('gender_model',overwrite=True)\n",
    "train.to_csv(\"train_split.csv\")\n",
    "test.to_csv(\"test_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = model.predict(test_X)\n",
    "prob_m = [i[0] for i in evals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(prob_m)\n",
    "out['name'] = test.name.reset_index()['name']\n",
    "out['m_or_f']=test.m_or_f.reset_index()['m_or_f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.head(10)\n",
    "out.columns = ['prob_m','name','actual']\n",
    "out.head(10)\n",
    "out.to_csv(\"gender_pred_out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
