<?xml version="1.0" encoding="UTF-8"?>
<mxGraphModel dx="1377" dy="745" grid="1" gridSize="10" guides="1" tooltips="1" connect="1" arrows="1" fold="1" page="1" pageScale="1" pageWidth="850" pageHeight="1100" math="0" shadow="0"><root><mxCell id="0"/><mxCell id="1" parent="0"/><mxCell id="nKZdOUqJn1gZBDkrh3-O-16" value="" style="edgeStyle=orthogonalEdgeStyle;rounded=0;html=1;jettySize=auto;orthogonalLoop=1;entryX=0.422;entryY=0.025;entryDx=0;entryDy=0;entryPerimeter=0;" edge="1" parent="1" source="nKZdOUqJn1gZBDkrh3-O-1" target="nKZdOUqJn1gZBDkrh3-O-5"><mxGeometry relative="1" as="geometry"/></mxCell><mxCell id="nKZdOUqJn1gZBDkrh3-O-1" value="Capture data from the EMA, from different individuals, based on MOCHA-TIMIT word vocabulary.&amp;nbsp;&lt;br&gt;Edit the data to remove the silence part of each recording, which is roughly around .12 seconds.&lt;br&gt;" style="rounded=0;whiteSpace=wrap;html=1;" vertex="1" parent="1"><mxGeometry x="110" y="150" width="690" height="120" as="geometry"/></mxCell><mxCell id="nKZdOUqJn1gZBDkrh3-O-3" value="EMA data capturing&amp;nbsp;" style="text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;" vertex="1" parent="1"><mxGeometry x="390" y="130" width="165" height="20" as="geometry"/></mxCell><mxCell id="nKZdOUqJn1gZBDkrh3-O-4" value="Feature extraction and Signal Processing" style="text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;" vertex="1" parent="1"><mxGeometry x="400" y="313" width="165" height="20" as="geometry"/></mxCell><mxCell id="nKZdOUqJn1gZBDkrh3-O-12" value="" style="edgeStyle=orthogonalEdgeStyle;rounded=0;html=1;jettySize=auto;orthogonalLoop=1;entryX=0.408;entryY=0;entryDx=0;entryDy=0;entryPerimeter=0;" edge="1" parent="1" source="nKZdOUqJn1gZBDkrh3-O-5" target="nKZdOUqJn1gZBDkrh3-O-7"><mxGeometry relative="1" as="geometry"/></mxCell><mxCell id="nKZdOUqJn1gZBDkrh3-O-5" value="Calculate MFCC features, and divide phoneme sequence calculated from kaldi into time based frame.&lt;br&gt;Divide each syllable, as many times as they occur in each of the time frame&lt;br&gt;" style="rounded=0;whiteSpace=wrap;html=1;" vertex="1" parent="1"><mxGeometry x="97.5" y="333" width="690" height="120" as="geometry"/></mxCell><mxCell id="nKZdOUqJn1gZBDkrh3-O-6" value="Further study and replicate TacoTron2 model, as it converts speech to mel spectogram, our purpose is somewhat similar, and we have to construct EMA trajectories from the phoneme sequence.&amp;nbsp;&lt;br&gt;" style="rounded=0;whiteSpace=wrap;html=1;" vertex="1" parent="1"><mxGeometry x="80" y="780" width="690" height="120" as="geometry"/></mxCell><mxCell id="nKZdOUqJn1gZBDkrh3-O-13" value="" style="edgeStyle=orthogonalEdgeStyle;rounded=0;html=1;jettySize=auto;orthogonalLoop=1;entryX=0.43;entryY=0.017;entryDx=0;entryDy=0;entryPerimeter=0;" edge="1" parent="1" source="nKZdOUqJn1gZBDkrh3-O-7" target="nKZdOUqJn1gZBDkrh3-O-6"><mxGeometry relative="1" as="geometry"/></mxCell><mxCell id="nKZdOUqJn1gZBDkrh3-O-7" value="Make a custom RNN as our input data doesn't follow the normal&amp;nbsp; batch major, timestep format.&amp;nbsp;&lt;br&gt;Create a multi layered bidirectional RNN, with parameters decided from GRIDSEARCH&lt;br&gt;" style="rounded=0;whiteSpace=wrap;html=1;" vertex="1" parent="1"><mxGeometry x="97.5" y="560" width="690" height="120" as="geometry"/></mxCell><mxCell id="nKZdOUqJn1gZBDkrh3-O-8" value="Construction of TacoTron 2 architecture.&amp;nbsp;" style="text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;" vertex="1" parent="1"><mxGeometry x="400" y="750" width="165" height="20" as="geometry"/></mxCell><mxCell id="nKZdOUqJn1gZBDkrh3-O-9" value="Basic structure and model, further feature processing" style="text;html=1;strokeColor=none;fillColor=none;align=center;verticalAlign=middle;whiteSpace=wrap;rounded=0;" vertex="1" parent="1"><mxGeometry x="400" y="530" width="165" height="20" as="geometry"/></mxCell></root></mxGraphModel>